\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Logistic Regression\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Pena Benafa}
\IEEEauthorblockA{\textit{Electronic Engineering} \\
\textit{University of Applied Science Hamm-Lippstadt}\\
Lippstadt, Germany \\
pena.benafa@stud.hshl.de}
}

\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}


\subsection{Machine Learning Algorithms and Examples}


\subsection{Description of the Classification Problem}


\section{Definition of Logistic Regression}

\subsection{Dependent Variables}

\subsection{Independent Variables}


\section{Logistic Regression Model}

\subsection{Regression Equation}

\subsection{Regression Curve}
\subsection{Decision Boundary}
\subsection{Non-Linear Decision Boundary}

\section{Cost Function and Gradient Descent}

\section{Over fitting Problem}
\subsection{Under Fitting}
\subsection{Over Fitting}

\section{Regularized Logistic Regression}

\section{Conclusion}


\section*{Acknowledgment}


%\section*{References}



\begin{thebibliography}{00}

\bibitem{b1} M. RAZA, N. D. Jayasinghe and M. M. A. Muslam, "A Comprehensive Review on Email Spam Classification using Machine Learning Algorithms," 2021 International Conference on Information Networking (ICOIN), 2021, pp. 327-332, doi: 10.1109/ICOIN50884.2021.9334020.

\bibitem{b2} Fanliang Bu and Qingmei Xie, "Research on emergency evacuation traffic trip generation forecasting based on Logistic regression," 2010 IEEE International Conference on Emergency Management and Management Sciences, 2010, pp. 504-507, doi: 10.1109/ICEMMS.2010.5563390.

\bibitem{b3} A. El-Koka, K. Cha and D. Kang, "Regularization parameter tuning optimization approach in logistic regression," 2013 15th International Conference on Advanced Communications Technology (ICACT), 2013, pp. 13-18.

\bibitem{b4} A. Wang, N. An, Y. Xia, L. Li and G. Chen, "A Logistic Regression and Artificial Neural Network-Based Approach for Chronic Disease Prediction: A Case Study of Hypertension," 2014 IEEE International Conference on Internet of Things (iThings), and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom), 2014, pp. 45-52, doi: 10.1109/iThings.2014.16.

\bibitem{b5} Menard, Scott. "Logistic Regression: From Introductory to Advanced Concepts and Applications." Indien, SAGE Publications, 2010.

\bibitem{b6} Hilbe, Joseph M.. "Logistic Regression Models." United Kingdom, CRC Press, 2009.

\bibitem{b7} Stephan Dreiseitl, Lucila Ohno-Machado, "Logistic regression and artificial neural network classification models: a methodology review", Journal of Biomedical Informatics, Volume 35, Issues 5–6, 2002, Pages 352-359, ISSN 1532-0464, doi.org/10.1016/S1532-0464(03)00034-0.

\bibitem{b8} Lever, J., Krzywinski, M. \& Altman, N. Logistic regression. Nat Methods 13, 541–542 (2016). https://doi.org/10.1038/nmeth.3904



\end{thebibliography}

\end{document}
